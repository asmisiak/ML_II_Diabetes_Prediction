{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     12\u001b[39m warnings.simplefilter(action=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, category=\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Input, SimpleRNN, LSTM, Reshape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Create a TF control dependency on the return values of a function.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03m  If the function had no return value, a no-op context is returned.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m    A context manager.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/python/ops/tensor_array_ops.py:36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_spec\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_spec_registry\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/python/ops/array_ops.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flags\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m d_api\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m record\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/dtensor/python/api.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Sequence\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtensor_device\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_dtensor_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout \u001b[38;5;28;01mas\u001b[39;00m layout_lib\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/dtensor/python/dtensor_device.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout \u001b[38;5;28;01mas\u001b[39;00m layout_lib\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_dtensor_device\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/STUDIA/HFD/ML_II_Diabetes_Prediction/.venv/lib/python3.12/site-packages/tensorflow/dtensor/python/layout.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout_pb2\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_dtensor_device\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device \u001b[38;5;28;01mas\u001b[39;00m tf_device\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import(\n",
    "    StandardScaler)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split)\n",
    "import statsmodels.formula.api as smf\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, SimpleRNN, LSTM, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/diabetes_dataset.csv\")\n",
    "\n",
    "df = df.drop(columns='diabetes_stage')\n",
    "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0, 'Other': 2})\n",
    "df['ethnicity'] = df['ethnicity'].map({'White' : 0, 'Hispanic' : 1, 'Black' : 2, 'Asian' : 3, 'Other' : 4})\n",
    "df['education_level'] = df['education_level'].map({'No formal' : 0, 'Highschool' : 1, 'Graduate' : 2, 'Postgraduate' : 3})\n",
    "df['income_level'] = df['income_level'].map({'Low' : 0, 'Lower-Middle' :1, 'Middle' : 2, 'Upper-Middle' : 3, 'High': 4})\n",
    "df['employment_status'] = df['employment_status'].map({'Employed' : 0, 'Unemployed' : 1, 'Retired': 2, 'Student':3})\n",
    "df['smoking_status'] = df['smoking_status'].map({'Never' : 0, 'Former' : 1, 'Current' : 2})\n",
    "df = df[df['gender'] != 2] #Removing\n",
    "\n",
    "# Define train and target \n",
    "target = df[['diagnosed_diabetes']]\n",
    "train = df.drop('diagnosed_diabetes', axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
    "\n",
    "#Division of dataset\n",
    "x_train_full, x_test = train_test_split(train, test_size=0.2, random_state=123)\n",
    "y_train_full, y_test = train_test_split(target, test_size=0.2, random_state=123)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step\n",
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260us/step\n",
      "Neural network results saved to neural_network_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the activation functions to test\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', 'elu', 'selu']\n",
    "\n",
    "# Function to create a model with a given activation function\n",
    "def create_model_1(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_2(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_3(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Compile and train the model\n",
    "def compile_and_train(model, x_train, y_train, x_val, y_val, epochs=20, batch_size=16):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['recall'])\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return accuracy, report['accuracy'], report['macro avg']['f1-score'], report['macro avg']['recall']\n",
    "\n",
    "# Example usage\n",
    "input_dim = x_train.shape[1]\n",
    "results_1 = {}\n",
    "results_2 = {}\n",
    "results_3 = {}\n",
    "\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_model_1(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_1[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n",
    "\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_model_2(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_2[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n",
    "\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_model_3(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_3[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n",
    "\n",
    "results_SequentialNN_1 = results_1\n",
    "results_SequentialNN_2 = results_2\n",
    "results_SequentialNN_3 = results_3\n",
    "\n",
    "# Save all neural network results to a pickle file\n",
    "nn_results = {\n",
    "    'Sequential_Model_1': results_SequentialNN_1,\n",
    "    'Sequential_Model_2': results_SequentialNN_2,\n",
    "    'Sequential_Model_3': results_SequentialNN_3\n",
    "}\n",
    "\n",
    "with open('neural_network_results_recall_batch32.pkl', 'wb') as f:\n",
    "    pickle.dump(nn_results, f)\n",
    "\n",
    "print(\"Neural network results saved to neural_network_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch size: 8\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270us/step\n",
      "Testing batch size: 16\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n",
      "Testing batch size: 32\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n",
      "Testing batch size: 64\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step\n",
      "Testing batch size: 8\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "Testing batch size: 16\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step\n",
      "Testing batch size: 32\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step\n",
      "Testing batch size: 64\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step\n",
      "Testing batch size: 8\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "Testing batch size: 16\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step\n",
      "Testing batch size: 32\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step\n",
      "Testing batch size: 64\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244us/step\n"
     ]
    }
   ],
   "source": [
    "# Define the activation functions to test\n",
    "activation_functions = ['relu']\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64]\n",
    "\n",
    "# Function to create a model with a given activation function\n",
    "def create_model_1(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_2(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_3(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Compile and train the model\n",
    "def compile_and_train(model, x_train, y_train, x_val, y_val, epochs=20, batch_size=16):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['recall'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0)\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return accuracy, report['accuracy'], report['macro avg']['f1-score'], report['macro avg']['recall']\n",
    "\n",
    "# Example usage\n",
    "input_dim = x_train.shape[1]\n",
    "results_1 = {}\n",
    "results_2 = {}\n",
    "results_3 = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size: {batch_size}\")\n",
    "    model = create_model_1(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val, batch_size=batch_size)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_1[batch_size] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size: {batch_size}\")\n",
    "    model = create_model_2(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val, batch_size=batch_size)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_2[batch_size] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing batch size: {batch_size}\")\n",
    "    model = create_model_3(input_dim, activation)\n",
    "    compile_and_train(model, x_train, y_train, x_val, y_val, batch_size=batch_size)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, x_test, y_test)\n",
    "    results_3[batch_size] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall' : recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: learning_rate=0.0001,loss=binary_crossentropy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting configuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m model = create_model(input_dim)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mcompile_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m accuracy, precision, f1_score = evaluate_model(model, x_test, y_test)\n\u001b[32m     49\u001b[39m results[config_name] = {\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: accuracy, \u001b[33m'\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m'\u001b[39m: f1_score}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mcompile_and_train\u001b[39m\u001b[34m(model, x_train, y_train, x_val, y_val, learning_rate, loss, epochs, batch_size)\u001b[39m\n\u001b[32m     19\u001b[39m model.compile(optimizer=optimizer,\n\u001b[32m     20\u001b[39m               loss=loss,\n\u001b[32m     21\u001b[39m               metrics=[tf.keras.metrics.F1Score()])\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.device(\u001b[33m'\u001b[39m\u001b[33m/GPU:0\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/DIABETES_PREDICTION/.venv/lib/python3.13/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define the learning rates and loss functions to test\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "loss_functions = ['binary_crossentropy', 'hinge']\n",
    "\n",
    "# Function to create a simple model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation='elu'),\n",
    "        Dense(64, activation='elu'),\n",
    "        Dense(32, activation='elu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "def compile_and_train(model, x_train, y_train, x_val, y_val, learning_rate, loss, epochs=20, batch_size=16):\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[tf.keras.metrics.F1Score()])\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    return accuracy, report['accuracy'], report['macro avg']['f1-score']\n",
    "\n",
    "# Example usage\n",
    "input_dim = x_train.shape[1]\n",
    "results = {}\n",
    "\n",
    "# Test different combinations of learning rates and loss functions\n",
    "for learning_rate in learning_rates:\n",
    "    for loss in loss_functions:\n",
    "        config_name = f\"learning_rate={learning_rate},loss={loss}\"\n",
    "        print(f\"Testing configuration: {config_name}\")\n",
    "        model = create_model(input_dim)\n",
    "        compile_and_train(model, x_train, y_train, x_val, y_val, learning_rate, loss)\n",
    "        accuracy, precision, f1_score = evaluate_model(model, x_test, y_test)\n",
    "        results[config_name] = {'accuracy': accuracy, 'f1_score': f1_score}\n",
    "\n",
    "results_LR_Loss = results \n",
    "\n",
    "# Save the results to a pickle file\n",
    "with open('nn_lr_loss_results_scaled_batch16.pkl', 'wb') as f:\n",
    "    pickle.dump(results_LR_Loss, f)\n",
    "print(\"Neural network learning rate and loss function results saved to nn_lr_loss_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation functions to test\n",
    "activation_functions = ['relu', 'sigmoid']\n",
    "\n",
    "# Function to create a model with a given activation function\n",
    "def create_model_1(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_2(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_3(input_dim, activation):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Enhanced compile and train function with EarlyStopping\n",
    "def compile_and_train_with_early_stopping(model, x_train, y_train, x_val, y_val, epochs=50, batch_size=16):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['recall'])\n",
    "    \n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',           # Monitor validation loss\n",
    "        patience=3,                   # Stop if no improvement for 3 consecutive epochs\n",
    "        restore_best_weights=True,    # Restore the best weights when stopping\n",
    "        verbose=1,                    # Print message when stopping\n",
    "        mode='min',                   # Stop when monitored quantity stops decreasing\n",
    "        min_delta=0.001               # Minimum change to qualify as improvement\n",
    "    )\n",
    "    \n",
    "    # Train model with callbacks\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0)\n",
    "    \n",
    "    return history, early_stopping.stopped_epoch\n",
    "\n",
    "# Enhanced evaluate function\n",
    "def evaluate_model_enhanced(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test, verbose=0) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        'accuracy': accuracy, \n",
    "        'f1_score': report['macro avg']['f1-score'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall']\n",
    "    }\n",
    "\n",
    "# Function to plot training history with early stopping indicator\n",
    "def plot_model_history(history, model_name, activation, stopped_epoch):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot F1 Score (since that's what we're monitoring)\n",
    "    ax1.plot(history.history['recall'], label='Training Recall', marker='o')\n",
    "    ax1.plot(history.history['val_recall'], label='Validation Recall', marker='s')\n",
    "    if stopped_epoch > 0:\n",
    "        ax1.axvline(x=stopped_epoch, color='red', linestyle='--', \n",
    "                   label=f'Early Stop (Epoch {stopped_epoch})')\n",
    "    ax1.set_title(f'{model_name} - {activation} - Recall')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Recall')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    if stopped_epoch > 0:\n",
    "        ax2.axvline(x=stopped_epoch, color='red', linestyle='--',\n",
    "                   label=f'Early Stop (Epoch {stopped_epoch})')\n",
    "    ax2.set_title(f'{model_name} - {activation} - Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "# Training function for each model architecture\n",
    "def train_model_architecture(model_creator, model_name, input_dim):\n",
    "    \n",
    "    results = {}\n",
    "    training_info = {}\n",
    "    \n",
    "    for activation in activation_functions:\n",
    "        print(f\"\\n Testing {model_name} with activation: {activation}\")\n",
    "        \n",
    "        # Create and train model\n",
    "        model = model_creator(input_dim, activation)\n",
    "        history, stopped_epoch = compile_and_train_with_early_stopping(\n",
    "            model, x_train, y_train, x_val, y_val, epochs=50\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model_enhanced(model, x_test, y_test)\n",
    "        \n",
    "        # Store results\n",
    "        results[activation] = metrics\n",
    "        training_info[activation] = {\n",
    "            'history': history,\n",
    "            'stopped_epoch': stopped_epoch,\n",
    "            'total_epochs': len(history.history['loss']),\n",
    "            'early_stopped': stopped_epoch > 0\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"   Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"   F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"   Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"   Epochs trained: {len(history.history['loss'])}\")\n",
    "        if stopped_epoch > 0:\n",
    "            print(f\"Early stopped at epoch: {stopped_epoch}\")\n",
    "        else:\n",
    "            print(f\"Completed all epochs\")\n",
    "    \n",
    "    return results, training_info\n",
    "\n",
    "\n",
    "# Main execution\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# Train all model architectures\n",
    "print(\"TRAINING NEURAL NETWORK MODELS WITH EARLY STOPPING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model 1: Simple model with dropout layers\n",
    "results_1, training_info_1 = train_model_architecture(\n",
    "    create_model_1, \"Model 1 (Simple with Dropout)\", input_dim\n",
    ")\n",
    "\n",
    "# Model 2: Deeper model with more neurons\n",
    "results_2, training_info_2 = train_model_architecture(\n",
    "    create_model_2, \"Model 2 (Deeper)\", input_dim\n",
    ")\n",
    "\n",
    "# Model 3: Smaller model with fewer neurons\n",
    "results_3, training_info_3 = train_model_architecture(\n",
    "    create_model_3, \"Model 3 (Smaller)\", input_dim\n",
    ")\n",
    "\n",
    "# Comprehensive results display\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE RESULTS WITH EARLY STOPPING\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "models_data = [\n",
    "    (\"Model 1 (Simple with Dropout)\", results_1, training_info_1),\n",
    "    (\"Model 2 (Deeper)\", results_2, training_info_2),\n",
    "    (\"Model 3 (Smaller)\", results_3, training_info_3)\n",
    "]\n",
    "\n",
    "best_overall = {'model': None, 'activation': None, 'f1_score': 0, 'recall': 0}\n",
    "\n",
    "for model_name, results, training_info in models_data:\n",
    "    print(f\"\\n {model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for activation, metrics in results.items():\n",
    "        info = training_info[activation]\n",
    "        print(f\"   {activation}:\")\n",
    "        print(f\"     Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"     F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"     Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"     Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"     Epochs: {info['total_epochs']} {'(Early Stopped)' if info['early_stopped'] else '(Full Training)'}\")\n",
    "        \n",
    "        # Track best overall performance\n",
    "        if metrics['f1_score'] > best_overall['f1_score']:\n",
    "            best_overall = {\n",
    "                'model': model_name,\n",
    "                'activation': activation,\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'recall': metrics['recall']\n",
    "            }\n",
    "\n",
    "# Display best overall model\n",
    "print(f\"\\n BEST OVERALL MODEL:\")\n",
    "print(f\"   Model: {best_overall['model']}\")\n",
    "print(f\"   Activation: {best_overall['activation']}\")\n",
    "print(f\"   F1-Score: {best_overall['f1_score']:.4f}\")\n",
    "print(f\"   Accuracy: {best_overall['accuracy']:.4f}\")\n",
    "print(f\"   Recall: {best_overall['recall']:.4f}\")\n",
    "\n",
    "# Early stopping statistics\n",
    "print(f\"\\n EARLY STOPPING STATISTICS:\")\n",
    "total_models = len(activation_functions) * 3\n",
    "early_stopped_count = 0\n",
    "total_epochs = 0\n",
    "\n",
    "for _, _, training_info in models_data:\n",
    "    for activation, info in training_info.items():\n",
    "        if info['early_stopped']:\n",
    "            early_stopped_count += 1\n",
    "        total_epochs += info['total_epochs']\n",
    "\n",
    "avg_epochs = total_epochs / total_models\n",
    "print(f\"   Total models trained: {total_models}\")\n",
    "print(f\"   Models early stopped: {early_stopped_count}/{total_models} ({early_stopped_count/total_models*100:.1f}%)\")\n",
    "print(f\"   Average epochs per model: {avg_epochs:.1f}\")\n",
    "\n",
    "# Plot training history for best model\n",
    "best_model_data = None\n",
    "best_training_info = None\n",
    "\n",
    "with open('nn_early_stopping_results_batch16_recall.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'models_data': models_data,\n",
    "        'best_overall': best_overall,\n",
    "        'early_stopping_stats': {\n",
    "            'total_models': total_models,\n",
    "            'early_stopped_count': early_stopped_count,\n",
    "            'average_epochs': total_epochs / total_models\n",
    "        }\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features based on MI score:\n",
      "['hba1c', 'glucose_postprandial', 'glucose_fasting', 'diabetes_risk_score', 'family_history_diabetes', 'age', 'gender', 'systolic_bp', 'ldl_cholesterol', 'physical_activity_minutes_per_week']\n",
      "Training set shape: (62711, 10)\n",
      "Validation set shape: (15678, 10)\n",
      "Test set shape: (19598, 10)\n",
      "\n",
      "Training Sequential NN models with MI-selected features:\n",
      "============================================================\n",
      "\n",
      "Model 1 (Simple with Dropout) - MI Features:\n",
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step\n",
      "\n",
      "Model 2 (Deeper) - MI Features:\n",
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step\n",
      "\n",
      "Model 3 (Smaller) - MI Features:\n",
      "Testing activation function: relu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step\n",
      "Testing activation function: sigmoid\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n",
      "Testing activation function: tanh\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step\n",
      "Testing activation function: elu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step\n",
      "Testing activation function: selu\n",
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step\n",
      "\n",
      "================================================================================\n",
      "RESULTS FOR MODELS TRAINED WITH MI-SELECTED FEATURES\n",
      "================================================================================\n",
      "\n",
      "Model 1 (Simple with dropout) - MI Features:\n",
      "Activation: relu, Accuracy: 0.8655, F1-Score: 0.9179, Recall: 0.9313\n",
      "Activation: sigmoid, Accuracy: 0.8491, F1-Score: 0.9071, Recall: 0.9218\n",
      "Activation: tanh, Accuracy: 0.8638, F1-Score: 0.9152, Recall: 0.9284\n",
      "Activation: elu, Accuracy: 0.8656, F1-Score: 0.9167, Recall: 0.9298\n",
      "Activation: selu, Accuracy: 0.8645, F1-Score: 0.9172, Recall: 0.9306\n",
      "\n",
      "Model 2 (Deeper) - MI Features:\n",
      "Activation: relu, Accuracy: 0.8646, F1-Score: 0.9171, Recall: 0.9305\n",
      "Activation: sigmoid, Accuracy: 0.8657, F1-Score: 0.9158, Recall: 0.9287\n",
      "Activation: tanh, Accuracy: 0.8634, F1-Score: 0.9168, Recall: 0.9304\n",
      "Activation: elu, Accuracy: 0.8655, F1-Score: 0.9167, Recall: 0.9299\n",
      "Activation: selu, Accuracy: 0.8628, F1-Score: 0.9164, Recall: 0.9301\n",
      "\n",
      "Model 3 (Smaller) - MI Features:\n",
      "Activation: relu, Accuracy: 0.8643, F1-Score: 0.9170, Recall: 0.9305\n",
      "Activation: sigmoid, Accuracy: 0.8634, F1-Score: 0.9139, Recall: 0.9269\n",
      "Activation: tanh, Accuracy: 0.8655, F1-Score: 0.9177, Recall: 0.9311\n",
      "Activation: elu, Accuracy: 0.8654, F1-Score: 0.9178, Recall: 0.9312\n",
      "Activation: selu, Accuracy: 0.8640, F1-Score: 0.9175, Recall: 0.9311\n",
      "\n",
      "Best MI-based model:\n",
      "Model: Model_1_MI\n",
      "Activation: relu\n",
      "F1-Score: 0.9179\n",
      "Accuracy: 0.8655\n",
      "Recall: 0.9313\n",
      "\n",
      "MI-based neural network results saved to neural_network_mi_results.pkl\n"
     ]
    }
   ],
   "source": [
    "feature_ranking = pd.read_csv(\"datageneral_ranking.csv\")\n",
    "\n",
    "\n",
    "# Get top features based on mutual information score\n",
    "top_features_mi = feature_ranking.nlargest(10, 'mi_score')['Unnamed: 0'].tolist()\n",
    "print(\"Top 10 features based on MI score:\")\n",
    "print(top_features_mi)\n",
    "\n",
    "# Prepare data with selected features\n",
    "X_mi = df[top_features_mi].values\n",
    "y_mi = df['diagnosed_diabetes'].values\n",
    "\n",
    "scale_mi = StandardScaler()\n",
    "X_mi = scale_mi.fit_transform(X_mi)\n",
    "\n",
    "# Split the data\n",
    "X_train_mi, X_test_mi, y_train_mi, y_test_mi = train_test_split(\n",
    "    X_mi, y_mi, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_mi, X_val_mi, y_train_mi, y_val_mi = train_test_split(\n",
    "    X_train_mi, y_train_mi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_mi.shape}\")\n",
    "print(f\"Validation set shape: {X_val_mi.shape}\")\n",
    "print(f\"Test set shape: {X_test_mi.shape}\")\n",
    "\n",
    "# Define Sequential NN models for MI-selected features\n",
    "def create_mi_model_1(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_mi_model_2(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_mi_model_3(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train models with MI-selected features\n",
    "input_dim_mi = X_train_mi.shape[1]\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', 'elu', 'selu']\n",
    "\n",
    "results_mi_1 = {}\n",
    "results_mi_2 = {}\n",
    "results_mi_3 = {}\n",
    "\n",
    "print(\"\\nTraining Sequential NN models with MI-selected features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model 1 with MI features\n",
    "print(\"\\nModel 1 (Simple with Dropout) - MI Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_mi_model_1(input_dim_mi, activation)\n",
    "    compile_and_train(model, X_train_mi, y_train_mi, X_val_mi, y_val_mi)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_mi, y_test_mi)\n",
    "    results_mi_1[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Model 2 with MI features\n",
    "print(\"\\nModel 2 (Deeper) - MI Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_mi_model_2(input_dim_mi, activation)\n",
    "    compile_and_train(model, X_train_mi, y_train_mi, X_val_mi, y_val_mi)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_mi, y_test_mi)\n",
    "    results_mi_2[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Model 3 with MI features\n",
    "print(\"\\nModel 3 (Smaller) - MI Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_mi_model_3(input_dim_mi, activation)\n",
    "    compile_and_train(model, X_train_mi, y_train_mi, X_val_mi, y_val_mi)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_mi, y_test_mi)\n",
    "    results_mi_3[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Display results for MI-based models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS FOR MODELS TRAINED WITH MI-SELECTED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('\\nModel 1 (Simple with dropout) - MI Features:')\n",
    "for activation, metrics in results_mi_1.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "print('\\nModel 2 (Deeper) - MI Features:')\n",
    "for activation, metrics in results_mi_2.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "print('\\nModel 3 (Smaller) - MI Features:')\n",
    "for activation, metrics in results_mi_3.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "# Find best performing model with MI features\n",
    "best_mi_model = {'model': None, 'activation': None, 'f1_score': 0, 'accuracy': 0, 'recall': 0}\n",
    "\n",
    "for model_name, results in [('Model_1_MI', results_mi_1), ('Model_2_MI', results_mi_2), ('Model_3_MI', results_mi_3)]:\n",
    "    for activation, metrics in results.items():\n",
    "        if metrics['f1_score'] > best_mi_model['f1_score']:\n",
    "            best_mi_model = {\n",
    "                'model': model_name,\n",
    "                'activation': activation,\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'recall': metrics['recall']\n",
    "            }\n",
    "\n",
    "print(f\"\\nBest MI-based model:\")\n",
    "print(f\"Model: {best_mi_model['model']}\")\n",
    "print(f\"Activation: {best_mi_model['activation']}\")\n",
    "print(f\"F1-Score: {best_mi_model['f1_score']:.4f}\")\n",
    "print(f\"Accuracy: {best_mi_model['accuracy']:.4f}\")\n",
    "print(f\"Recall: {best_mi_model['recall']:.4f}\")\n",
    "\n",
    "# Save MI-based results\n",
    "results_MI_NN = {\n",
    "    'Sequential_MI_Model_1': results_mi_1,\n",
    "    'Sequential_MI_Model_2': results_mi_2,\n",
    "    'Sequential_MI_Model_3': results_mi_3,\n",
    "    'best_model': best_mi_model,\n",
    "    'selected_features': top_features_mi\n",
    "}\n",
    "\n",
    "with open('neural_network_mi_results_scaled_recall_batch16.pkl', 'wb') as f:\n",
    "    pickle.dump(results_MI_NN, f)\n",
    "\n",
    "print(\"\\nMI-based neural network results saved to neural_network_mi_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top features based on mutual information score\n",
    "top_features_boruta = feature_ranking.nsmallest(15, 'boruta_rank')['Unnamed: 0'].tolist()\n",
    "print(\"Top 10 features based on Boruta score:\")\n",
    "print(top_features_boruta)\n",
    "\n",
    "# Prepare data with selected features\n",
    "X_boruta = df[top_features_boruta].values\n",
    "y_boruta = df['diagnosed_diabetes'].values\n",
    "\n",
    "scale_boruta = StandardScaler()\n",
    "X_boruta = scale_boruta.fit_transform(X_boruta)\n",
    "\n",
    "# Split the data\n",
    "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(\n",
    "    X_boruta, y_boruta, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_boruta, X_val_boruta, y_train_boruta, y_val_boruta = train_test_split(\n",
    "    X_train_boruta, y_train_boruta, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_boruta.shape}\")\n",
    "print(f\"Validation set shape: {X_val_boruta.shape}\")\n",
    "print(f\"Test set shape: {X_test_boruta.shape}\")\n",
    "\n",
    "# Define Sequential NN models for MI-selected features\n",
    "def create_boruta_model_1(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_boruta_model_2(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_boruta_model_3(input_dim, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train models with MI-selected features\n",
    "input_dim_boruta = X_train_boruta.shape[1]\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', 'elu', 'selu']\n",
    "\n",
    "results_boruta_1 = {}\n",
    "results_boruta_2 = {}\n",
    "results_boruta_3 = {}\n",
    "\n",
    "print(\"\\nTraining Sequential NN models with Boruta-selected features:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model 1 with MI features\n",
    "print(\"\\nModel 1 (Simple with Dropout) - Boruta Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_boruta_model_1(input_dim_boruta, activation)\n",
    "    compile_and_train(model, X_train_boruta, y_train_boruta, X_val_boruta, y_val_boruta)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_boruta, y_test_boruta)\n",
    "    results_boruta_1[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Model 2 with MI features\n",
    "print(\"\\nModel 2 (Deeper) - MI Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_boruta_model_2(input_dim_boruta, activation)\n",
    "    compile_and_train(model, X_train_boruta, y_train_boruta, X_val_boruta, y_val_boruta)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_boruta, y_test_boruta)\n",
    "    results_boruta_2[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Model 3 with MI features\n",
    "print(\"\\nModel 3 (Smaller) - MI Features:\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"Testing activation function: {activation}\")\n",
    "    model = create_boruta_model_3(input_dim_boruta, activation)\n",
    "    compile_and_train(model, X_train_boruta, y_train_boruta, X_val_boruta, y_val_boruta)\n",
    "    accuracy, precision, f1_score, recall = evaluate_model(model, X_test_boruta, y_test_boruta)\n",
    "    results_boruta_3[activation] = {'accuracy': accuracy, 'f1_score': f1_score, 'recall': recall}\n",
    "\n",
    "# Display results for MI-based models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS FOR MODELS TRAINED WITH MI-SELECTED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('\\nModel 1 (Simple with dropout) - MI Features:')\n",
    "for activation, metrics in results_boruta_1.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "print('\\nModel 2 (Deeper) - MI Features:')\n",
    "for activation, metrics in results_boruta_2.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "print('\\nModel 3 (Smaller) - MI Features:')\n",
    "for activation, metrics in results_boruta_3.items():\n",
    "    print(f\"Activation: {activation}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}, Recall: {metrics['recall']:.4f}\")\n",
    "\n",
    "# Find best performing model with Boruta features\n",
    "best_boruta_model = {'model': None, 'activation': None, 'f1_score': 0, 'accuracy': 0}\n",
    "\n",
    "for model_name, results in [('Model_1_Boruta', results_boruta_1), ('Model_2_Boruta', results_boruta_2), ('Model_3_Boruta', results_boruta_3)]:\n",
    "    for activation, metrics in results.items():\n",
    "        if metrics['f1_score'] > best_boruta_model['f1_score']:\n",
    "            best_boruta_model = {\n",
    "                'model': model_name,\n",
    "                'activation': activation,\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'recall': metrics['recall']\n",
    "            }\n",
    "\n",
    "print(f\"\\nBest Boruta based model:\")\n",
    "print(f\"Model: {best_boruta_model['model']}\")\n",
    "print(f\"Activation: {best_boruta_model['activation']}\")\n",
    "print(f\"F1-Score: {best_boruta_model['f1_score']:.4f}\")\n",
    "print(f\"Accuracy: {best_boruta_model['accuracy']:.4f}\")\n",
    "print(f\"Recall: {best_boruta_model['recall']:.4f}\")\n",
    "\n",
    "# Save MI-based results\n",
    "results_boruta_NN = {\n",
    "    'Sequential_boruta_Model_1': results_boruta_1,\n",
    "    'Sequential_boruta_Model_2': results_boruta_2,\n",
    "    'Sequential_boruta_Model_3': results_boruta_3,\n",
    "    'best_model': best_boruta_model,\n",
    "    'selected_features': top_features_boruta}\n",
    "\n",
    "with open('neural_network_boruta_results_scaled_batch16.pkl', 'wb') as f:\n",
    "    pickle.dump(results_boruta_NN, f)\n",
    "\n",
    "print(\"\\nBoruta-based neural network results saved to neural_network_boruta_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Architectures\n",
    "def create_lstm_model_1(input_dim, activation='relu', lstm_units=64):\n",
    "    \"\"\"Simple LSTM model with dropout\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Reshape((input_dim, 1)),  # Reshape for LSTM (timesteps, features)\n",
    "        LSTM(lstm_units, activation=activation, return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model_2(input_dim, activation='relu', lstm_units=64):\n",
    "    \"\"\"Stacked LSTM model\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Reshape((input_dim, 1)),\n",
    "        LSTM(lstm_units, activation=activation, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(lstm_units//2, activation=activation, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model_3(input_dim, activation='relu', lstm_units=32):\n",
    "    \"\"\"Bidirectional LSTM model\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Reshape((input_dim, 1)),\n",
    "        tf.keras.layers.Bidirectional(LSTM(lstm_units, activation=activation)),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model_4(input_dim, activation='relu', lstm_units=48):\n",
    "    \"\"\"Deep LSTM with multiple layers\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Reshape((input_dim, 1)),\n",
    "        LSTM(lstm_units, activation=activation, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(lstm_units//2, activation=activation, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(lstm_units//4, activation=activation, return_sequences=False),\n",
    "        Dense(16, activation=activation),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Enhanced training function with early stopping\n",
    "def compile_and_train_lstm_with_early_stopping(model, x_train, y_train, x_val, y_val, \n",
    "                                              epochs=100, batch_size=16, patience=5):\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['recall']\n",
    "    )\n",
    "    \n",
    "    # Enhanced EarlyStopping for LSTM\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        min_delta=0.0001\n",
    "    )\n",
    "    \n",
    "    # Additional callback for learning rate reduction\n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=patience//2,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            validation_data=(x_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping, lr_scheduler],\n",
    "            verbose=0\n",
    "        )\n",
    "    \n",
    "    return history, early_stopping.stopped_epoch\n",
    "\n",
    "# Enhanced evaluation function\n",
    "def evaluate_lstm_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test, verbose=0) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': report['macro avg']['f1-score'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall'],\n",
    "        'loss': loss\n",
    "    }\n",
    "\n",
    "# Visualization function for LSTM training\n",
    "def plot_lstm_history(history, model_name, activation, lstm_units, stopped_epoch):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs_range = range(1, len(history.history['loss']) + 1)\n",
    "    \n",
    "    # Training & Validation Accuracy\n",
    "    ax1.plot(epochs_range, history.history['recall'], 'bo-', label='Training Accuracy')\n",
    "    ax1.plot(epochs_range, history.history['val_recall'], 'ro-', label='Validation Accuracy')\n",
    "    if stopped_epoch > 0:\n",
    "        ax1.axvline(x=stopped_epoch, color='green', linestyle='--', \n",
    "                   label=f'Early Stop (Epoch {stopped_epoch})')\n",
    "    ax1.set_title(f'{model_name} - {activation} (Units: {lstm_units}) - recall')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Recall')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training & Validation Loss\n",
    "    ax2.plot(epochs_range, history.history['loss'], 'bo-', label='Training Loss')\n",
    "    ax2.plot(epochs_range, history.history['val_loss'], 'ro-', label='Validation Loss')\n",
    "    if stopped_epoch > 0:\n",
    "        ax2.axvline(x=stopped_epoch, color='green', linestyle='--',\n",
    "                   label=f'Early Stop (Epoch {stopped_epoch})')\n",
    "    ax2.set_title(f'{model_name} - {activation} (Units: {lstm_units}) - Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate (if available)\n",
    "    if 'lr' in history.history:\n",
    "        ax3.plot(epochs_range, history.history['lr'], 'go-', label='Learning Rate')\n",
    "        ax3.set_title('Learning Rate Schedule')\n",
    "        ax3.set_xlabel('Epochs')\n",
    "        ax3.set_ylabel('Learning Rate')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Learning Rate\\nNot Recorded', \n",
    "                ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.set_title('Learning Rate')\n",
    "    \n",
    "    # Training Progress Summary\n",
    "    final_train_acc = history.history['recall'][-1]\n",
    "    final_val_acc = history.history['val_recall'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    Final Training Recall: {final_train_acc:.4f}\n",
    "    Final Validation Recall: {final_val_acc:.4f}\n",
    "    Final Training Loss: {final_train_loss:.4f}\n",
    "    Final Validation Loss: {final_val_loss:.4f}\n",
    "    Total Epochs: {len(history.history['loss'])}\n",
    "    Early Stopped: {'Yes' if stopped_epoch > 0 else 'No'}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.1, 0.5, summary_text, transform=ax4.transAxes, fontsize=12, \n",
    "             verticalalignment='center', fontfamily='monospace')\n",
    "    ax4.set_title('Training Summary')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main LSTM training execution\n",
    "print(\" TRAINING LSTM MODELS WITH BORUTA-SELECTED FEATURES AND EARLY STOPPING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define configurations\n",
    "activation_functions = ['relu', 'sigmoid']\n",
    "lstm_units_options = [32, 64, 96]\n",
    "model_creators = [\n",
    "    ('LSTM_Model_1_Simple', create_lstm_model_1),\n",
    "    ('LSTM_Model_2_Stacked', create_lstm_model_2),\n",
    "    ('LSTM_Model_3_Bidirectional', create_lstm_model_3),\n",
    "    ('LSTM_Model_4_Deep', create_lstm_model_4)\n",
    "]\n",
    "\n",
    "# Initialize results storage\n",
    "results_lstm= {}\n",
    "training_histories_lstm = {}\n",
    "best_lstm_model = {'model': None, 'config': None, 'f1_score': 0, 'accuracy': 0, 'recall': 0}\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "\n",
    "# Train all LSTM model configurations\n",
    "for model_name, model_creator in model_creators:\n",
    "    print(f\"\\n  Training {model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    results_lstm[model_name] = {}\n",
    "    training_histories_lstm[model_name] = {}\n",
    "    \n",
    "    for activation in activation_functions:\n",
    "        for lstm_units in lstm_units_options:\n",
    "            config_key = f\"{activation}_units_{lstm_units}\"\n",
    "            print(f\"  🔧 Configuration: {activation} activation, {lstm_units} LSTM units\")\n",
    "            \n",
    "            try:\n",
    "                # Create and train model\n",
    "                model = model_creator(input_dim, activation, lstm_units)\n",
    "                history, stopped_epoch = compile_and_train_lstm_with_early_stopping(\n",
    "                    model, x_train, y_train, x_val, y_val,\n",
    "                    epochs=100, batch_size=8, patience=7\n",
    "                )\n",
    "                \n",
    "                # Evaluate model\n",
    "                metrics = evaluate_lstm_model(model, x_test, y_test)\n",
    "                \n",
    "                # Store results\n",
    "                results_lstm[model_name][config_key] = metrics\n",
    "                training_histories_lstm[model_name][config_key] = {\n",
    "                    'history': history,\n",
    "                    'stopped_epoch': stopped_epoch,\n",
    "                    'total_epochs': len(history.history['loss'])\n",
    "                }\n",
    "                \n",
    "                # Update best model\n",
    "                if metrics['f1_score'] > best_lstm_model['f1_score']:\n",
    "                    best_lstm_model = {\n",
    "                        'model': model_name,\n",
    "                        'config': config_key,\n",
    "                        'f1_score': metrics['f1_score'],\n",
    "                        'accuracy': metrics['accuracy'],\n",
    "                        'recall': metrics['recall'],\n",
    "                        'activation': activation,\n",
    "                        'lstm_units': lstm_units\n",
    "                    }\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"     F1-Score: {metrics['f1_score']:.4f}\")\n",
    "                print(f\"     Accuracy: {metrics['accuracy']:.4f}\")\n",
    "                print(f\"     Recall: {metrics['recall']:.4f}\")\n",
    "                print(f\"     Epochs: {len(history.history['loss'])}\")\n",
    "                if stopped_epoch > 0:\n",
    "                    print(f\"     Early stopped at epoch: {stopped_epoch}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"     Error: {str(e)}\")\n",
    "                results_lstm[model_name][config_key] = {\n",
    "                    'accuracy': 0, 'f1_score': 0, 'precision': 0, 'recall': 0, 'loss': float('inf')\n",
    "                }\n",
    "\n",
    "\n",
    "# Save LSTM results\n",
    "results_lstm_complete = {\n",
    "    'model_results': results_lstm,\n",
    "    'training_histories': training_histories_lstm,\n",
    "    'best_model': best_lstm_model,\n",
    "    'input_dimension': input_dim\n",
    "}\n",
    "\n",
    "with open('lstm_results_batch16_recall.pkl', 'wb') as f:\n",
    "    pickle.dump(results_lstm_complete, f)\n",
    "\n",
    "print(f\"\\n LSTM results saved to lstm_results.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the activation functions to test\n",
    "activation_functions = ['relu', 'sigmoid']\n",
    "\n",
    "# Function to create an RNN model with a given configuration\n",
    "def create_rnn_model(input_shape, units, activation, num_layers, dropout_rate):\n",
    "    model = Sequential()\n",
    "    # Reshape 2D input to 3D for RNN (add timesteps dimension)\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(tf.keras.layers.Reshape((input_shape[0], 1)))  # (features, 1) for timesteps\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        model.add(SimpleRNN(units, activation=activation, return_sequences=(i < num_layers - 1)))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "def compile_and_train(model, x_train, y_train, x_val, y_val, epochs=15, batch_size=16):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.F1Score()])\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    return accuracy, report['accuracy'], report['macro avg']['f1-score']\n",
    "\n",
    "# Make sure you have your data loaded and split before this point\n",
    "# Example usage (assuming x_train, y_train, x_val, y_val, x_test, y_test are defined)\n",
    "input_shape = (x_train.shape[1],)  # Note: single dimension tuple\n",
    "results = {}\n",
    "\n",
    "#Test different configurations\n",
    "for activation in activation_functions:\n",
    "    for units in [16, 32, 64]:\n",
    "        for num_layers in [1, 2, 3]:\n",
    "            for dropout_rate in [0.0, 0.3]:\n",
    "                config_name = f\"activation={activation},units={units},layers={num_layers},dropout={dropout_rate}\"\n",
    "                print(f\"Testing configuration: {config_name}\")\n",
    "                model = create_rnn_model(input_shape, units, activation, num_layers, dropout_rate)\n",
    "                compile_and_train(model, x_train, y_train, x_val, y_val)\n",
    "                accuracy, precision, f1_score = evaluate_model(model, x_test, y_test)\n",
    "                results[config_name] = {'accuracy': accuracy, 'f1_score': f1_score}\n",
    "\n",
    "# Display results\n",
    "print('RNN Model Results:')\n",
    "for config, metrics in results.items():\n",
    "   print(f\"Config: {config}, Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Save RNN results\n",
    "with open('rnn_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"RNN results saved to rnn_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
